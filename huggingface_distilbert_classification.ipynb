{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "huggingface_distilbert_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPugV5/VsP/E+bdoF6+F91n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmgyorke/distilbert-base-sequence-classification/blob/main/huggingface_distilbert_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKFuxfDutZ8K",
        "outputId": "6a05ee01-4ace-4834-d6e8-0abc66fd1bf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "RirLgTp7tb22"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\", model = model_name, tokenizer = tokenizer)\n",
        "results = classifier([\"He saved the drowning child.\", \n",
        "                      \"She filed a lawsuit.\", \n",
        "                      \"Marcel won the gold medal.\",\n",
        "                      \"The store was way too crowded.\"])\n",
        "\n",
        "for result in results:\n",
        "  print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io8wPEGHtfVZ",
        "outputId": "f32c8035-1800-4cce-9a89-790f7f2da2a7"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'label': 'POSITIVE', 'score': 0.9972121119499207}\n",
            "{'label': 'NEGATIVE', 'score': 0.9983137845993042}\n",
            "{'label': 'POSITIVE', 'score': 0.9997240900993347}\n",
            "{'label': 'NEGATIVE', 'score': 0.9997655749320984}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.tokenize(\"He saved the drowning child.\")\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "input_ids = tokenizer(\"He saved the drowning child.\")\n",
        "\n",
        "print(f'  Tokens: {tokens}')\n",
        "print(f'Token IDs: {token_ids}')\n",
        "print(f'Input IDs: {input_ids}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTofapS_uXPb",
        "outputId": "07e039f3-81ec-4649-dfdb-d7e0a1d4b59f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Tokens: ['he', 'saved', 'the', 'drowning', 'child', '.']\n",
            "Token IDs: [2002, 5552, 1996, 14759, 2775, 1012]\n",
            "Input IDs: {'input_ids': [101, 2002, 5552, 1996, 14759, 2775, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = [\"He saved the drowning child.\", \n",
        "           \"She filed a lawsuit.\", \n",
        "           \"Marcel won the gold medal.\", \n",
        "           \"There were many books in the library.\"]\n",
        "\n",
        "batch = tokenizer(X_train, padding = True, truncation = True, max_length = 512, return_tensors = \"pt\")\n",
        "print(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrRdJHpG02fn",
        "outputId": "7a058bb6-bc95-4add-8773-ef9fd827b0a1"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,  2002,  5552,  1996, 14759,  2775,  1012,   102,     0,     0],\n",
            "        [  101,  2016,  6406,  1037,  9870,  1012,   102,     0,     0,     0],\n",
            "        [  101, 13389,  2180,  1996,  2751,  3101,  1012,   102,     0,     0],\n",
            "        [  101,  2045,  2020,  2116,  2808,  1999,  1996,  3075,  1012,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    outputs = model(**batch)\n",
        "    print(outputs)\n",
        "    predictions = F.softmax(outputs.logits, dim = 1) \n",
        "    print(predictions)\n",
        "    labels = torch.argmax(predictions, dim = 1)\n",
        "    print(labels)\n",
        "    labels = [model.config.id2label[label_id] for label_id in labels.tolist()]\n",
        "    print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7GLAfVT2Omu",
        "outputId": "99c6d05a-a7c7-4c67-88aa-f3f1e1ed8671"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SequenceClassifierOutput(loss=None, logits=tensor([[-2.9233,  2.9563],\n",
            "        [ 3.5349, -2.8486],\n",
            "        [-4.0332,  4.1618],\n",
            "        [ 0.7429, -0.6320]]), hidden_states=None, attentions=None)\n",
            "tensor([[2.7879e-03, 9.9721e-01],\n",
            "        [9.9831e-01, 1.6862e-03],\n",
            "        [2.7595e-04, 9.9972e-01],\n",
            "        [7.9817e-01, 2.0183e-01]])\n",
            "tensor([1, 0, 1, 0])\n",
            "['POSITIVE', 'NEGATIVE', 'POSITIVE', 'NEGATIVE']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_directory = \"saved\"\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "model.save_pretrained(save_directory)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(save_directory)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(save_directory)"
      ],
      "metadata": {
        "id": "4PU_SXBO8dqe"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's try a model trained on a Spanish language corpus"
      ],
      "metadata": {
        "id": "GAB3qMjEaq1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"dpalominop/spanish-bert-apoyo\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "X_train_spanish = [\"ayer gané la carrera.\", \n",
        "          \"ella lloró cuando se cayó.\", \n",
        "          \"gracias por la planta que me diste.\", \n",
        "          \"la guerra cobró muchas vidas.\"]\n",
        "\n",
        "batch = tokenizer(X_train_spanish, padding = True, truncation = True, max_length = 512, return_tensors = \"pt\")\n",
        "print(batch)\n",
        "\n",
        "with torch.no_grad():\n",
        "     outputs = model(**batch)\n",
        "     print(outputs)\n",
        "     predictions = F.softmax(outputs.logits, dim = 1) \n",
        "     print(predictions)\n",
        "     labels = torch.argmax(predictions, dim = 1)\n",
        "     print(labels)\n",
        "     labels = [model.config.id2label[label_id] for label_id in labels.tolist()]\n",
        "     print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGqhWtBdZQra",
        "outputId": "8839ec78-a2c1-44e9-d454-ee151ce6ac10"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[    4,  5023, 19593,  1032,  3630,  1008,     5,     1,     1,     1],\n",
            "        [    4,  1512,  4878, 30957,  1351,  1057, 24959,  1008,     5,     1],\n",
            "        [    4,  1542,  1076,  1032,  5340,  1041,  1094,  9669,  1008,     5],\n",
            "        [    4,  1032,  2274, 22181,  2458,  5394,  1008,     5,     1,     1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])}\n",
            "SequenceClassifierOutput(loss=None, logits=tensor([[-2.6419, -0.2875,  1.2996],\n",
            "        [ 0.2926,  1.2322, -2.0869],\n",
            "        [-2.9871,  0.0106,  1.0275],\n",
            "        [-0.9706,  0.3721, -0.5588]]), hidden_states=None, attentions=None)\n",
            "tensor([[0.0159, 0.1671, 0.8170],\n",
            "        [0.2739, 0.7008, 0.0254],\n",
            "        [0.0131, 0.2622, 0.7248],\n",
            "        [0.1578, 0.6041, 0.2381]])\n",
            "tensor([2, 1, 2, 1])\n",
            "['LABEL_2', 'LABEL_1', 'LABEL_2', 'LABEL_1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sentence translation Spanish - English:\n",
        "\n",
        "\"ayer gané la carrera.\" = \"i won the race yesterday.\"\n",
        "\n",
        "\"ella lloró cuando se cayó.\" = \"she cried when she fell.\"\n",
        "\n",
        "\"gracias por la planta que me diste.\" = \"thank you for the plant you gave me.\"\n",
        "\n",
        "\"la guerra cobró muchas vidas.\" = \"the war cost many lives.\""
      ],
      "metadata": {
        "id": "qSBqx-sNZkhd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Labels\n",
        "\n",
        "In the config file of this model (\"dpalominop/spanish-bert-apoyo\") - hugging face hub\n",
        "\n",
        "These labels are shown:\n",
        "\n",
        "- \"0\": \"LABEL_0\"\n",
        "- \"1\": \"LABEL_1\"\n",
        "- \"2\": \"LABEL_2\"\n",
        "\n",
        "I will assume this mapping:\n",
        "\n",
        "- Label_1 = Negative\n",
        "- Label_2 = Positive\n",
        "\n",
        "## !Salud!"
      ],
      "metadata": {
        "id": "9LQhOsUpaA-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "f6KBuOgiaRg2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}